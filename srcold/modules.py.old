# Definition of several convolutional modules
# Normal convolution, Residual, ResNeXt, Inception, Amoeba...
# From [this link](https://towardsdatascience.com/history-of-convolutional-blocks-in-simple-code-96a7ddceac0c).

import numpy as np
import keras
import keras.layers
import keras.backend


################################################################################################################################################################################
def StemModule(m_name):
    def VanillaStem(x, n_filters, ker_size, kernel_init='glorot_uniform'):
        m = keras.layers.Conv1D(n_filters, ker_size, padding='same', kernel_initializer=kernel_init)(x)
        m = keras.layers.ReLU()(m)
        m = keras.layers.BatchNormalization()(m)

        m = keras.layers.Conv1D(n_filters, ker_size, padding='same', kernel_initializer=kernel_init)(m)
        return m

    def ResidualStem(x, n_filters, ker_size, kernel_init='glorot_uniform'):
        m = keras.layers.Conv1D(n_filters, ker_size, padding='same', kernel_initializer=kernel_init)(x)
        m = keras.layers.ReLU()(m)
        m = keras.layers.BatchNormalization()(m)

        m = keras.layers.Conv1D(n_filters, ker_size, padding='same', kernel_initializer=kernel_init)(m)
        return m

    def XCeptionStem(x, n_filters, ker_size, kernel_init='glorot_uniform'):
        m = keras.layers.SeparableConv1D(n_filters, ker_size, padding='same', strides=(1,), kernel_initializer=kernel_init)(x)
        m = keras.layers.ReLU()(m)
        m = keras.layers.BatchNormalization()(m)

        m = keras.layers.SeparableConv1D(n_filters, ker_size, padding='same', strides=(1,), kernel_initializer=kernel_init)(m)
        return m

    if (m_name.lower() == 'vanilla'):
        return VanillaStem
    elif (m_name.lower() == 'residual'):
        return ResidualStem
    elif (m_name.lower() == 'xception'):
        return XCeptionStem
    else:
        raise ValueError('Module name not correctly specified')
        

################################################################################################################################################################################
def LevelModule(m_name):
    def VanillaLevelBlock(x, n_filters, ker_size, kernel_init='glorot_uniform'):
        m = keras.layers.ReLU()(x)
        m = keras.layers.BatchNormalization()(m)
        m = keras.layers.Conv1D(n_filters, 3, padding='same', kernel_initializer=kernel_init)(m)

        m = keras.layers.ReLU()(m)
        m = keras.layers.BatchNormalization()(m)
        m = keras.layers.Conv1D(n_filters, 3, padding='same', kernel_initializer=kernel_init)(m)
        return m

    def ResidualLevelBlock(x, n_filters, ker_size, kernel_init='glorot_uniform'):
        m = keras.layers.ReLU()(x)
        m = keras.layers.BatchNormalization()(m)
        m = keras.layers.Conv1D(n_filters, ker_size, padding='same', strides=(1,), kernel_initializer=kernel_init)(m)

        m = keras.layers.ReLU()(m)
        m = keras.layers.BatchNormalization()(m)
        m = keras.layers.Conv1D(n_filters, ker_size, padding='same', strides=(1,), kernel_initializer=kernel_init)(m)
        
        if (x.shape[-1] != n_filters):
            x = keras.layers.ReLU()(x)
            x = keras.layers.BatchNormalization()(x)
            x = keras.layers.Conv1D(n_filters, kernel_size=(1,), padding='same')(x)

        return keras.layers.add([x, m])

    def XCeptionLevelBlock(x, n_filters, ker_size, kernel_init='glorot_uniform', AAAAAAAA=False):
        m = keras.layers.ReLU()(x)
        m = keras.layers.BatchNormalization()(m)
        m = keras.layers.SeparableConv1D(n_filters, ker_size, padding='same', strides=(1,), kernel_initializer=kernel_init)(m)

        m = keras.layers.ReLU()(m)
        m = keras.layers.BatchNormalization()(m)
        m = keras.layers.SeparableConv1D(n_filters, ker_size, padding='same', strides=(1,), kernel_initializer=kernel_init)(m)
        
        if (x.shape[-1] != n_filters):
            x = keras.layers.ReLU()(x)
            x = keras.layers.BatchNormalization()(x)
            x = keras.layers.SeparableConv1D(n_filters, kernel_size=(1,), padding='same')(x)

        return keras.layers.add([x, m])

    if (m_name.lower() == 'vanilla'):
        return VanillaLevelBlock
    elif (m_name.lower() == 'residual'):
        return ResidualLevelBlock
    elif (m_name.lower() == 'xception'):
        return XCeptionLevelBlock
    else:
        raise ValueError('Module name not correctly specified')
        
     
def AtrousMiddleModule(m_name):
    def VanillaAtrousBlock(x, n_filters, ker_size, kernel_init='glorot_uniform'):
        m    = keras.layers.ReLU()(x)
        m    = keras.layers.BatchNormalization()(m)
        m1   = keras.layers.Conv1D(n_filters, 1,        dilation_rate=1,   padding='same', strides=(1,), kernel_initializer=kernel_init)(m)
        m6   = keras.layers.Conv1D(n_filters, ker_size, dilation_rate=6,   padding='same', strides=(1,), kernel_initializer=kernel_init)(m)
        m12  = keras.layers.Conv1D(n_filters, ker_size, dilation_rate=12,  padding='same', strides=(1,), kernel_initializer=kernel_init)(m)
        m18  = keras.layers.Conv1D(n_filters, ker_size, dilation_rate=18,  padding='same', strides=(1,), kernel_initializer=kernel_init)(m)
        mgap = keras.layers.GlobalAveragePooling1D()(m1) if (m.shape[1] != n_filters) else keras.layers.GlobalAveragePooling1D()(m)
        mgap = keras.layers.RepeatVector(m.shape[1].value)(mgap)
        m    = keras.layers.Concatenate()([m1,m6,m12,m18,mgap])
        return m

    def ResidualAtrousBlock(x, n_filters, ker_size, kernel_init='glorot_uniform'):
        m    = keras.layers.ReLU()(x)
        m    = keras.layers.BatchNormalization()(m)
        m1   = keras.layers.Conv1D(n_filters, 1,        dilation_rate=1,   padding='same', strides=(1,), kernel_initializer=kernel_init)(m)
        m6   = keras.layers.Conv1D(n_filters, ker_size, dilation_rate=6,   padding='same', strides=(1,), kernel_initializer=kernel_init)(m)
        m12  = keras.layers.Conv1D(n_filters, ker_size, dilation_rate=12,  padding='same', strides=(1,), kernel_initializer=kernel_init)(m)
        m18  = keras.layers.Conv1D(n_filters, ker_size, dilation_rate=18,  padding='same', strides=(1,), kernel_initializer=kernel_init)(m)
        mgap = keras.layers.GlobalAveragePooling1D()(m1) if (m.shape[1] != n_filters) else keras.layers.GlobalAveragePooling1D()(m)
        mgap = keras.layers.RepeatVector(m.shape[1].value)(mgap)
        m    = keras.layers.Concatenate()([m1,m6,m12,m18,mgap])
        return m

    def XCeptionAtrousBlock(x, n_filters, ker_size, kernel_init='glorot_uniform'):
        # XCeption Atrous Spatial Pyramid Pooling
        m    = keras.layers.ReLU()(x)
        m    = keras.layers.BatchNormalization()(m)
        m1   = keras.layers.SeparableConv1D(n_filters, 1,        dilation_rate=1,  padding='same', strides=(1,), kernel_initializer=kernel_init)(m)
        m6   = keras.layers.SeparableConv1D(n_filters, ker_size, dilation_rate=6,  padding='same', strides=(1,), kernel_initializer=kernel_init)(m)
        m12  = keras.layers.SeparableConv1D(n_filters, ker_size, dilation_rate=12, padding='same', strides=(1,), kernel_initializer=kernel_init)(m)
        m18  = keras.layers.SeparableConv1D(n_filters, ker_size, dilation_rate=18, padding='same', strides=(1,), kernel_initializer=kernel_init)(m)
        mgap = keras.layers.GlobalAveragePooling1D()(m1) if (m.shape[1] != n_filters) else keras.layers.GlobalAveragePooling1D()(m)
        mgap = keras.layers.RepeatVector(m.shape[1].value)(mgap)
        m    = keras.layers.Concatenate()([m1,m6,m12,m18,mgap])
        return m


    if (m_name.lower() == 'vanilla'):
        return VanillaAtrousBlock
    elif (m_name.lower() == 'residual'):
        return ResidualAtrousBlock
    elif (m_name.lower() == 'xception'):
        return XCeptionAtrousBlock
    else:
        raise ValueError('Module name not correctly specified')
        

################################################################################################################################################################################
def PoolingModule(m_name):
    def VanillaPoolingBlock(x, n_filters, ker_size, maxpool, strides=(2,), kernel_init='glorot_uniform'):
        m = keras.layers.ReLU()(x)
        m = keras.layers.BatchNormalization()(m)
        m = keras.layers.Conv1D(n_filters, ker_size, padding='same', strides=(1,), kernel_initializer=kernel_init)(m)

        m = keras.layers.ReLU()(m)
        m = keras.layers.BatchNormalization()(m)
        m = keras.layers.Conv1D(n_filters, ker_size, padding='same', strides=(1,), kernel_initializer=kernel_init)(m)

        if maxpool: m = keras.layers.MaxPooling1D(pool_size=ker_size, padding='same', strides=strides)(m)
        else:       m = keras.layers.AveragePooling1D(pool_size=ker_size, padding='same', strides=strides)(m)

        return m

    def ResidualPoolingBlock(x, n_filters, ker_size, maxpool, strides=(2,), kernel_init='glorot_uniform'):
        m = keras.layers.ReLU()(x)
        m = keras.layers.BatchNormalization()(m)
        m = keras.layers.Conv1D(n_filters, ker_size, padding='same', kernel_initializer=kernel_init)(m)

        m = keras.layers.ReLU()(m)
        m = keras.layers.BatchNormalization()(m)
        m = keras.layers.Conv1D(n_filters, ker_size, padding='same', kernel_initializer=kernel_init)(m)

        if maxpool: m = keras.layers.MaxPooling1D(pool_size=ker_size, padding='same', strides=strides)(m)
        else:       m = keras.layers.AveragePooling1D(pool_size=ker_size, padding='same', strides=strides)(m)

        x = keras.layers.ReLU()(x)
        x = keras.layers.BatchNormalization()(x)
        x = keras.layers.Conv1D(n_filters, kernel_size=(1,), strides=(2,), padding='same')(x)

        return keras.layers.add([x, m])

    def XCeptionPoolingBlock(x, n_filters, ker_size, maxpool, strides=(2,), kernel_init='glorot_uniform'):
        m = keras.layers.ReLU()(x)
        m = keras.layers.BatchNormalization()(m)
        m = keras.layers.SeparableConv1D(n_filters, ker_size, padding='same', kernel_initializer=kernel_init)(m)

        m = keras.layers.ReLU()(m)
        m = keras.layers.BatchNormalization()(m)
        m = keras.layers.SeparableConv1D(n_filters, ker_size, padding='same', kernel_initializer=kernel_init)(m)

        if maxpool: m = keras.layers.MaxPooling1D(pool_size=ker_size, padding='same', strides=strides)(m)
        else:       m = keras.layers.AveragePooling1D(pool_size=ker_size, padding='same', strides=strides)(m)

        x = keras.layers.ReLU()(x)
        x = keras.layers.BatchNormalization()(x)
        x = keras.layers.SeparableConv1D(n_filters, kernel_size=(1,), strides=(2,), padding='same')(x)

        return keras.layers.add([x, m])

    if m_name.lower() == 'vanilla':
        return VanillaPoolingBlock
    elif (m_name.lower() == 'residual'):
        return ResidualPoolingBlock
    elif (m_name.lower() == 'xception'):
        return XCeptionPoolingBlock
    else:
        return VanillaPoolingBlock
     


def OutputModule(m_name, regression=False):
    def VanillaOutputBlock(x, n_filters, ker_size, kernel_init='glorot_uniform'):
        m = keras.layers.ReLU()(x)
        m = keras.layers.BatchNormalization()(m)
        m = keras.layers.Conv1D(n_filters, 1, padding='same', strides=(1,), activation='sigmoid', kernel_initializer=kernel_init)(m)
        return m

    def ResidualOutputBlock(x, n_filters, ker_size, kernel_init='glorot_uniform'):
        m = keras.layers.ReLU()(x)
        m = keras.layers.BatchNormalization()(m)
        m = keras.layers.Conv1D(n_filters, 1, padding='same', strides=(1,), activation='sigmoid', kernel_initializer=kernel_init)(m)
        return m

    def XCeptionOutputBlock(x, n_filters, ker_size, kernel_init='glorot_uniform'):
        m = keras.layers.ReLU()(x)
        m = keras.layers.BatchNormalization()(m)
        m = keras.layers.SeparableConv1D(n_filters, 1, padding='same', strides=(1,), activation='sigmoid', kernel_initializer=kernel_init)(m)
        return m

    if (m_name.lower() == 'vanilla'):
        return VanillaOutputBlock
    elif (m_name.lower() == 'residual'):
        return ResidualOutputBlock
    elif (m_name.lower() == 'xception'):
        return XCeptionOutputBlock
    else:
        raise ValueError('Module name not correctly specified')
        
    
