{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import random\n",
    "import uuid\n",
    "import os\n",
    "import os.path\n",
    "import skimage\n",
    "import sak\n",
    "import sak.wavelet\n",
    "import sak.data\n",
    "import sak.data.augmentation\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.signal\n",
    "import pandas as pd\n",
    "import networkx\n",
    "import networkx.algorithms.approximation\n",
    "import wfdb\n",
    "import json\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from sak.signal import StandardHeader\n",
    "\n",
    "# Data loader to un-clutter code    \n",
    "def load_data(filepath):\n",
    "    dic = dict()\n",
    "    with open(filepath) as f:\n",
    "        text = list(f)\n",
    "    for line in text:\n",
    "        line = line.replace(' ','').replace('\\n','').replace(',,','')\n",
    "        if line[-1] == ',': line = line[:-1]\n",
    "        head = line.split(',')[0]\n",
    "        tail = line.split(',')[1:]\n",
    "        if tail == ['']:\n",
    "            tail = np.asarray([])\n",
    "        else:\n",
    "            tail = np.asarray(tail).astype(int)\n",
    "\n",
    "        dic[head] = tail\n",
    "    return dic\n",
    "\n",
    "\n",
    "def trailonset(sig,on):\n",
    "    on = on-sig[0]\n",
    "    off = on-sig[0]+sig[-1]\n",
    "    sig = sig+np.linspace(on,off,sig.size)\n",
    "    \n",
    "    return sig\n",
    "\n",
    "def getcorr(segments):\n",
    "    if len(segments) > 0:\n",
    "        length = 2*max([segments[i][2].size for i in range(len(segments))])\n",
    "    else:\n",
    "        return np.zeros((0,0))\n",
    "\n",
    "    corr = np.zeros((len(segments),len(segments)))\n",
    "\n",
    "    for i in range(len(segments)):\n",
    "        for j in range(len(segments)):\n",
    "            if i != j:\n",
    "                if segments[i][2].size != segments[j][2].size:\n",
    "                    if segments[i][2].size != 1:\n",
    "                        x1 = sp.interpolate.interp1d(np.linspace(0,1,len(segments[i][2])),segments[i][2])(np.linspace(0,1,length))\n",
    "                    else:\n",
    "                        x1 = np.full((length,),segments[i][2][0])\n",
    "                    if segments[j][2].size != 1:\n",
    "                        x2 = sp.interpolate.interp1d(np.linspace(0,1,len(segments[j][2])),segments[j][2])(np.linspace(0,1,length))\n",
    "                    else:\n",
    "                        x2 = np.full((length,),segments[j][2][0])\n",
    "                else:\n",
    "                    x1 = segments[i][2]\n",
    "                    x2 = segments[j][2]\n",
    "                if (x1.size == 1) and (x2.size == 1):\n",
    "                    corr[i,j] = 1\n",
    "                else:\n",
    "                    c,_ = sak.signal.xcorr(x1,x2)\n",
    "                    corr[i,j] = np.max(np.abs(c))\n",
    "            else:\n",
    "                corr[i,j] = 1\n",
    "                \n",
    "    return corr\n",
    "\n",
    "def getdelete(segments, threshold):\n",
    "    corr = getcorr(segments)\n",
    "    \n",
    "    index_delete = []\n",
    "    \n",
    "    for i in range(corr.shape[0]):\n",
    "        if i in index_delete:\n",
    "            continue\n",
    "        for j in range(corr.shape[1]):\n",
    "            if j == i:\n",
    "                continue\n",
    "            if corr[i,j] > threshold:\n",
    "                if j not in index_delete:\n",
    "                    index_delete.append(j)\n",
    "                \n",
    "    return index_delete\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if platform.system() in ['Linux', 'Linux2']:\n",
    "    basedir = '/media/guille/DADES/DADES/Delineator'\n",
    "else:\n",
    "    basedir = r'C:\\Users\\Emilio\\Documents\\DADES\\DADES\\Delineator'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'agakjdsgklj' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-0cf3f0046eea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;31m# Store group\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0magakjdsgklj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'agakjdsgklj' is not defined"
     ]
    }
   ],
   "source": [
    "Pamplitudes = {}\n",
    "QRSamplitudes = {}\n",
    "Tamplitudes = {}\n",
    "\n",
    "for i in tqdm.tqdm(range(200)):\n",
    "    (signal, header) = wfdb.rdsamp(os.path.join(basedir,'ludb','{}'.format(i+1)))\n",
    "    sortOrder = np.where(np.array([x.upper() for x in header['sig_name']])[:,None] == StandardHeader)[1]\n",
    "    signal = signal[:,sortOrder]\n",
    "    if header['fs'] != 500:\n",
    "        print(header['fs'])\n",
    "    signal = sp.signal.decimate(signal,2,axis=0)\n",
    "    \n",
    "    # 1st step: reduce noise\n",
    "    signal = sp.signal.filtfilt(*sp.signal.butter(4,   0.5/250., 'high'),signal.T).T\n",
    "    signal = sp.signal.filtfilt(*sp.signal.butter(4, 125.0/250.,  'low'),signal.T).T\n",
    "    \n",
    "    Psegments   = [[] for _ in StandardHeader]\n",
    "    QRSsegments = [[] for _ in StandardHeader]\n",
    "    Tsegments   = [[] for _ in StandardHeader]\n",
    "\n",
    "    # 2nd step: retrieve onsets and offsets\n",
    "    for j in range(len(StandardHeader)):\n",
    "        lead = StandardHeader[j]\n",
    "        name = str(i+1)+\"_\"+lead\n",
    "        ann = wfdb.rdann(os.path.join(basedir,'ludb','{}'.format(i+1)),'atr_{}'.format(lead.lower()))\n",
    "        \n",
    "        locP = np.where(np.array(ann.symbol) == 'p')[0]\n",
    "        if len(locP) != 0:\n",
    "            if locP[0]-1 < 0:\n",
    "                locP = locP[1:]\n",
    "            if locP[-1]+1 == len(ann.sample):\n",
    "                locP = locP[:-1]\n",
    "        Pon[name] = ann.sample[locP-1]//2\n",
    "        Ppeak[name] = ann.sample[locP]//2\n",
    "        Poff[name] = ann.sample[locP+1]//2\n",
    "\n",
    "        locQRS = np.where(np.array(ann.symbol) == 'N')[0]\n",
    "        if len(locQRS) != 0:\n",
    "            if locQRS[0]-1 < 0:\n",
    "                locQRS = locQRS[1:]\n",
    "            if locQRS[-1]+1 == len(ann.sample):\n",
    "                locQRS = locQRS[:-1]\n",
    "        QRSon[name] = ann.sample[locQRS-1]//2\n",
    "        QRSpeak[name] = ann.sample[locQRS]//2\n",
    "        QRSoff[name] = ann.sample[locQRS+1]//2\n",
    "        \n",
    "        for k in range(len(locQRS)):\n",
    "            QRSsegments[j].append\n",
    "\n",
    "        locT = np.where(np.array(ann.symbol) == 't')[0]\n",
    "        if len(locT) != 0:\n",
    "            if locT[0]-1 < 0:\n",
    "                locT = locT[1:]\n",
    "            if locT[-1]+1 == len(ann.sample):\n",
    "                locT = locT[:-1]\n",
    "        Ton[name] = ann.sample[locT-1]//2\n",
    "        Tpeak[name] = ann.sample[locT]//2\n",
    "        Toff[name] = ann.sample[locT+1]//2\n",
    "        \n",
    "        # Store group\n",
    "        group[name] = str(i+1)\n",
    "        agakjdsgklj\n",
    "\n",
    "dataset = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 12)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 320,  662,  990, 1312, 1648, 1976])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.sample[locQRS-1]//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 626,  955, 1269, 1612, 1941])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.sample[locP-1]//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 386,  728, 1059, 1379, 1717])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.sample[locT-1]//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1_I': array([ 320,  662,  990, 1312, 1648, 1976])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning3",
   "language": "python",
   "name": "deeplearning3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
