{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import random\n",
    "import uuid\n",
    "import os\n",
    "import os.path\n",
    "import skimage\n",
    "import skimage.segmentation\n",
    "import torch\n",
    "import utils\n",
    "import utils.wavelet\n",
    "import utils.data\n",
    "import utils.data.augmentation\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.signal\n",
    "import pandas as pd\n",
    "import networkx\n",
    "import networkx.algorithms.approximation\n",
    "import wfdb\n",
    "import json\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from utils.signal import StandardHeader\n",
    "from scipy.stats import lognorm, norm, halfnorm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileUNet(torch.nn.Module):\n",
    "    '''Model'''\n",
    "\n",
    "    def __init__(self, config):\n",
    "        '''Initialization'''\n",
    "        super(MobileUNet, self).__init__()\n",
    "\n",
    "        # Parameters\n",
    "        self.m_name         = config.m_name\n",
    "        self.m_repetitions  = config.m_repetitions\n",
    "        self.out_ch         = config.out_ch\n",
    "        self.start_ch       = config.start_ch\n",
    "        self.kernel_size    = config.kernel_size\n",
    "        self.depth          = config.depth\n",
    "        self.inc_rate       = config.inc_rate\n",
    "        self.maxpool        = config.maxpool\n",
    "        self.kernel_init    = config.kernel_init\n",
    "\n",
    "        # Storing the architecture\n",
    "        self.encoder_levels = torch.nn.ModuleList([torch.nn.ModuleList() for i in range(self.depth)])\n",
    "        self.decoder_levels = torch.nn.ModuleList([torch.nn.ModuleList() for i in range(self.depth-1)])  # The encoder \"contains\" the bottleneck level\n",
    "        self.encoder_transitions = torch.nn.ModuleList([torch.nn.ModuleList() for i in range(self.depth)])\n",
    "        self.decoder_transitions = torch.nn.ModuleList([torch.nn.ModuleList() for i in range(self.depth)])\n",
    "\n",
    "        # Easing the notation\n",
    "        StemBlock = StemModule(self.m_name)\n",
    "        ConvBlock = LevelModule(self.m_name)\n",
    "        AtrousBlock = AtrousMiddleModule(self.m_name)\n",
    "        UpsamplingBlock = torch.nn.modules.Upsample\n",
    "        MaxAvgPool1d = torch.nn.MaxPool1d if self.maxpool else torch.nn.AvgPool1d\n",
    "        OutputBlock = OutputModule(self.m_name, self.regression)\n",
    "\n",
    "        ################### ARCHITECTURE DEFINITION ###################\n",
    "        # Up and downsampling blocks\n",
    "        [[self.encoder_transitions[i].append(MaxAvgPool1d(int(self.inc_rate**(self.depth-j)))) for j in range(self.depth-1, i, -1)[::-1]] for i in range(0, self.depth)]\n",
    "        [[self.decoder_transitions[i].append(UpsamplingBlock(scale_factor=int(self.inc_rate**(j+1)))) for j in range(0, i)[::-1]] for i in range(0, self.depth)]\n",
    "\n",
    "        # Channel contribution of different additions\n",
    "        skipped_con_ch = [int((self.inc_rate**i)*self.start_ch) for i in range(self.depth-1)]\n",
    "        dense_accum_ch = [0 for i in range(self.depth)]\n",
    "        mulscale_up_ch = [0 for i in range(self.depth)]\n",
    "        decoder_1st_ch = [0 for i in range(self.depth-1)]\n",
    "\n",
    "        #### STEM ####\n",
    "        # Apply stem\n",
    "        self.encoder_levels[0].append(StemBlock(1, int(self.start_ch//self.inc_rate), self.kernel_size, self.kernel_init))\n",
    "\n",
    "        #### ENCODER ####\n",
    "        # Encoder levels\n",
    "        for i in range(self.depth):\n",
    "            # Output Channels for this level\n",
    "            out_channels = int((self.inc_rate**i)*self.start_ch)\n",
    "\n",
    "            for j in range(self.m_repetitions):\n",
    "                # Input channels for this block\n",
    "                in_channels = int((self.inc_rate**(i - (j == 0)))*self.start_ch)\n",
    "                in_channels += int(self.hyperdense*dense_accum_ch[i])\n",
    "\n",
    "                # Encoder - levels\n",
    "                if (i != self.depth-1):  # Encoder levels\n",
    "                    self.encoder_levels[i].append(ConvBlock(in_channels, out_channels, self.kernel_size, self.kernel_init))\n",
    "                else:  # Embedding level (deepmost)\n",
    "                    if (j == self.m_repetitions - 1) and self.atrous_conv:\n",
    "                        self.encoder_levels[i].append(AtrousBlock(in_channels, out_channels, self.kernel_size, self.kernel_init))\n",
    "                    else:\n",
    "                        self.encoder_levels[i].append(ConvBlock(in_channels, out_channels, self.kernel_size, self.kernel_init))\n",
    "\n",
    "                # Update dense connection accumulator\n",
    "                dense_accum_ch[i] = in_channels\n",
    "\n",
    "            # Update dense connection accumulator\n",
    "            dense_accum_ch[i] += int(out_channels * (1 + 4*(i == self.depth-1)*self.atrous_conv))\n",
    "\n",
    "        #### DECODER ####\n",
    "        # Store the last block channels\n",
    "        decoder_1st_ch[-1] = int(out_channels * (1 + 4*(i == self.depth-1)*self.atrous_conv))\n",
    "\n",
    "        # Multiscale upsampling\n",
    "        for j in range(self.depth-3, -1, -1):\n",
    "            mulscale_up_ch[j] += int(out_channels * (1 + 4*(i == self.depth-1)*self.atrous_conv))\n",
    "\n",
    "        # Decoder levels\n",
    "        for i in range(self.depth-1)[::-1]:\n",
    "            # Output Channels for this level\n",
    "            out_channels = int((self.inc_rate**i)*self.start_ch)\n",
    "\n",
    "            for j in range(self.m_repetitions):\n",
    "                # Input channels for this block\n",
    "                in_channels  = int((j == 0)*decoder_1st_ch[i] + (j != 0)*(self.inc_rate**i)*self.start_ch)\n",
    "                in_channels += int((j == 0)*skipped_con_ch[i])\n",
    "                in_channels += int((j == 0)*self.ms_upsampling*mulscale_up_ch[i])\n",
    "                in_channels += int(self.hyperdense*(dense_accum_ch[i] - (j == 0)*skipped_con_ch[i]))\n",
    "\n",
    "                # Decoder - levels\n",
    "                if i != self.depth-1: self.decoder_levels[i].append(ConvBlock(in_channels, out_channels, self.kernel_size, self.kernel_init))\n",
    "\n",
    "                # Update dense connection accumulator\n",
    "                dense_accum_ch[i] = in_channels\n",
    "\n",
    "            if i != 0: decoder_1st_ch[i-1] = out_channels\n",
    "\n",
    "            # Update dense connection accumulator\n",
    "            dense_accum_ch[i] += out_channels\n",
    "\n",
    "            # Multiscale upsampling\n",
    "            for j in range(i-2, -1, -1):\n",
    "                mulscale_up_ch[j] += out_channels\n",
    "\n",
    "        in_channels = int((1-self.hyperdense)*self.start_ch + self.hyperdense*dense_accum_ch[0])\n",
    "        self.decoder_levels[0].append(OutputBlock(in_channels, 3, kernel_size=3, regression=self.regression, kernel_init='xavier_uniform'))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Store state of the input\n",
    "        encoder_path = [[] for i in range(self.depth)]\n",
    "        decoder_path = [[] for i in range(self.depth-1)]\n",
    "        upsampl_path = [[] for i in range(self.depth-1)]\n",
    "\n",
    "        # Divide in hyperdense/not to optimize GPU memory\n",
    "        if self.hyperdense:\n",
    "            encoder_path = [[] for i in range(self.depth)]\n",
    "            decoder_path = [[] for i in range(self.depth-1)]\n",
    "            if self.ms_upsampling: upsampl_path = [[] for i in range(self.depth-1)]\n",
    "\n",
    "            #### ENCODER ####\n",
    "            for i in range(len(self.encoder_levels)):\n",
    "                for j in range(len(self.encoder_levels[i])):\n",
    "                    if (i == 0) and (j == 0):  # Apply the stem\n",
    "                        encoder_path[i].append(self.encoder_levels[i][j](x))\n",
    "                    else:  # Do the usual\n",
    "                        encoder_path[i].append(self.encoder_levels[i][j](torch.cat(encoder_path[i], 1)))\n",
    "\n",
    "                if (i != len(self.encoder_levels) - 1):\n",
    "                    encoder_path[i+1].append(self.encoder_transitions[i][-1](encoder_path[i][-1]))\n",
    "                else:\n",
    "                    decoder_path[i-1].append(self.decoder_transitions[i][-1](encoder_path[i][-1]))\n",
    "                    if self.ms_upsampling: [upsampl_path[j].append(self.decoder_transitions[i][j](encoder_path[i][-1])) for j in range(i-2, -1, -1)]\n",
    "\n",
    "            #### DECODER ####\n",
    "            for i in range(len(self.decoder_levels))[::-1]:\n",
    "                for j in range(len(self.decoder_levels[i])):\n",
    "                    if self.ms_upsampling: decoder_path[i].append(self.decoder_levels[i][j](torch.cat(encoder_path[i] + decoder_path[i] + upsampl_path[i], 1)))\n",
    "                    else:                 decoder_path[i].append(self.decoder_levels[i][j](torch.cat(encoder_path[i] + decoder_path[i], 1)))\n",
    "\n",
    "                if (i != 0):\n",
    "                    decoder_path[i-1].append(self.decoder_transitions[i][-1](decoder_path[i][-1]))\n",
    "\n",
    "                # Multiscale Upsampling\n",
    "                if self.ms_upsampling: [upsampl_path[j].append(self.decoder_transitions[i][j](decoder_path[i][-1])) for j in range(i-2, -1, -1)]\n",
    "\n",
    "            return decoder_path[0][-1]\n",
    "        else: # IF IT IS NOT HYPERDENSE\n",
    "            skipped_path = []\n",
    "            if self.ms_upsampling: upsampl_path = [[] for i in range(self.depth-1)]\n",
    "\n",
    "            #### ENCODER ####\n",
    "            for i in range(len(self.encoder_levels)):\n",
    "                for j in range(len(self.encoder_levels[i])):\n",
    "                    x = self.encoder_levels[i][j](x)\n",
    "\n",
    "                skipped_path.append(x)\n",
    "\n",
    "                if (i != len(self.encoder_levels) - 1):\n",
    "                    x = self.encoder_transitions[i][-1](x)\n",
    "                else:\n",
    "                    if self.ms_upsampling: [upsampl_path[j].append(self.decoder_transitions[i][j](x)) for j in range(i-2, -1, -1)]\n",
    "                    x = self.decoder_transitions[i][-1](x)\n",
    "\n",
    "            #### DECODER ####\n",
    "            for i in range(len(self.decoder_levels))[::-1]:\n",
    "                for j in range(len(self.decoder_levels[i])):\n",
    "                    if self.ms_upsampling and (j == 0): x = self.decoder_levels[i][j](torch.cat([skipped_path[i], x] + upsampl_path[i], 1))\n",
    "                    elif (j == 0):                     x = self.decoder_levels[i][j](torch.cat([skipped_path[i], x], 1))\n",
    "                    else:                              x = self.decoder_levels[i][j](x)\n",
    "\n",
    "                # Multiscale Upsampling\n",
    "                if self.ms_upsampling: [upsampl_path[j].append(self.decoder_transitions[i][j](x)) for j in range(i-2, -1, -1)]\n",
    "                if (i != 0):          x = self.decoder_transitions[i][-1](x)\n",
    "\n",
    "            return x\n",
    "\n",
    "    def Export(self, path):\n",
    "        with open(path,'wb') as f:\n",
    "            printDict                                               = dict()\n",
    "            printDict['Architecture_IsHyperDense:               ']  = self.hyperdense\n",
    "            printDict['Architecture_HasAtrousLayer:             ']  = self.atrous_conv\n",
    "            printDict['Architecture_HasMultiscaleUpsampling:    ']  = self.ms_upsampling\n",
    "            printDict['Architecture_Depth:                      ']  = self.depth\n",
    "            printDict['Architecture_OutputChannels:             ']  = self.out_ch\n",
    "            printDict['Architecture_StartingChannels:           ']  = self.start_ch\n",
    "            printDict['Architecture_ChannelIncrementRate:       ']  = self.inc_rate\n",
    "            printDict['Architecture_HasMaxPool:                 ']  = self.maxpool\n",
    "            printDict['Architecture_KernelInitializer:          ']  = self.kernel_init\n",
    "            printDict['Module_Name:                             ']  = self.m_name\n",
    "            printDict['Module_Repetitions:                      ']  = self.m_repetitions\n",
    "            printDict['Module_KernelSize:                       ']  = self.kernel_size\n",
    "\n",
    "            w = csv.writer(f)\n",
    "            w.writerows(printDict.items())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MobileNetV2()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning3",
   "language": "python",
   "name": "deeplearning3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
