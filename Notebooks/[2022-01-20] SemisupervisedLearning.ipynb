{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import skimage\n",
    "import skimage.segmentation\n",
    "import sklearn.preprocessing\n",
    "import sklearn.model_selection\n",
    "import math\n",
    "import shutil\n",
    "import pathlib\n",
    "import glob\n",
    "import shutil\n",
    "import uuid\n",
    "import random\n",
    "import platform\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.io\n",
    "import scipy.signal\n",
    "import pandas as pd\n",
    "import networkx\n",
    "import wfdb\n",
    "import fleetfmt\n",
    "import json\n",
    "import tqdm\n",
    "import dill\n",
    "import pickle\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "import src.data\n",
    "import src.reader\n",
    "\n",
    "import sak\n",
    "import sak.signal.wavelet\n",
    "import sak.data\n",
    "import sak.data.augmentation\n",
    "import sak.visualization\n",
    "import sak.visualization.signal\n",
    "import sak.torch\n",
    "import sak.torch.nn\n",
    "import sak.torch.nn as nn\n",
    "import sak.torch.train\n",
    "import sak.torch.data\n",
    "import sak.data.preprocessing\n",
    "import sak.torch.models\n",
    "import sak.torch.models.lego\n",
    "import sak.torch.models.variational\n",
    "import sak.torch.models.classification\n",
    "\n",
    "from sak.signal import StandardHeader\n",
    "\n",
    "def smooth(x: np.ndarray, window_size: int, conv_mode: str = 'same'):\n",
    "    x = np.pad(np.copy(x),(window_size,window_size),'edge')\n",
    "    window = np.hamming(window_size)/(window_size//2)\n",
    "    x = np.convolve(x, window, mode=conv_mode)\n",
    "    x = x[window_size:-window_size]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From train_multi.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [00:00<00:00, 2315.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Issue with file sel35_0, continuing...\n",
      "Issue with file sel35_1, continuing...\n",
      "################# FOLD 1 #################\n"
     ]
    }
   ],
   "source": [
    "bool_hpc    = False\n",
    "model_name  = \"TestSemiSupervisedLearning\"\n",
    "config_file = './configurations/WNet6Levels.json'\n",
    "input_files = './pickle/'\n",
    "\n",
    "##### 1. Load configuration file #####\n",
    "with open(config_file, \"r\") as f:\n",
    "    execution = json.load(f)\n",
    "\n",
    "execution[\"root_directory\"] = os.path.expanduser(execution[\"root_directory\"])\n",
    "execution[\"save_directory\"] = os.path.expanduser(execution[\"save_directory\"])\n",
    "\n",
    "# NO ITERATOR FOR HPC, WASTE OF MEMORY\n",
    "if bool_hpc:\n",
    "    execution[\"iterator\"] = \"none\"\n",
    "\n",
    "##### 2. Load synthetic dataset #####\n",
    "# 2.1. Load individual segments\n",
    "P = sak.pickleload(os.path.join(input_files,\"Psignal_new.pkl\"))\n",
    "PQ = sak.pickleload(os.path.join(input_files,\"PQsignal_new.pkl\"))\n",
    "QRS = sak.pickleload(os.path.join(input_files,\"QRSsignal_new.pkl\"))\n",
    "ST = sak.pickleload(os.path.join(input_files,\"STsignal_new.pkl\"))\n",
    "T = sak.pickleload(os.path.join(input_files,\"Tsignal_new.pkl\"))\n",
    "TP = sak.pickleload(os.path.join(input_files,\"TPsignal_new.pkl\"))\n",
    "\n",
    "Pamplitudes = sak.pickleload(os.path.join(input_files,\"Pamplitudes_new.pkl\"))\n",
    "PQamplitudes = sak.pickleload(os.path.join(input_files,\"PQamplitudes_new.pkl\"))\n",
    "QRSamplitudes = sak.pickleload(os.path.join(input_files,\"QRSamplitudes_new.pkl\"))\n",
    "STamplitudes = sak.pickleload(os.path.join(input_files,\"STamplitudes_new.pkl\"))\n",
    "Tamplitudes = sak.pickleload(os.path.join(input_files,\"Tamplitudes_new.pkl\"))\n",
    "TPamplitudes = sak.pickleload(os.path.join(input_files,\"TPamplitudes_new.pkl\"))\n",
    "\n",
    "# 2.2. Get amplitude distribution\n",
    "Pdistribution   = scipy.stats.lognorm(*scipy.stats.lognorm.fit(np.array(list(Pamplitudes.values()))))\n",
    "PQdistribution  = scipy.stats.lognorm(*scipy.stats.lognorm.fit(np.array(list(PQamplitudes.values()))))\n",
    "QRSdistribution = scipy.stats.lognorm(*scipy.stats.lognorm.fit(np.hstack((np.array(list(QRSamplitudes.values())), 2-np.array(list(QRSamplitudes.values()))))))\n",
    "STdistribution  = scipy.stats.lognorm(*scipy.stats.lognorm.fit(np.array(list(STamplitudes.values()))))\n",
    "Tdistribution   = scipy.stats.lognorm(*scipy.stats.lognorm.fit(np.array(list(Tamplitudes.values()))))\n",
    "TPdistribution  = scipy.stats.lognorm(*scipy.stats.lognorm.fit(np.array(list(TPamplitudes.values()))))\n",
    "\n",
    "# 2.3. Smooth all\n",
    "window = 5\n",
    "P   = {k: sak.data.ball_scaling(sak.signal.on_off_correction(smooth(  P[k],window)),metric=sak.signal.abs_max) for k in   P}\n",
    "PQ  = {k: sak.data.ball_scaling(sak.signal.on_off_correction(smooth( PQ[k],window)),metric=sak.signal.abs_max) for k in  PQ}\n",
    "QRS = {k: sak.data.ball_scaling(sak.signal.on_off_correction(smooth(QRS[k],window)),metric=sak.signal.abs_max) for k in QRS}\n",
    "ST  = {k: sak.data.ball_scaling(sak.signal.on_off_correction(smooth( ST[k],window)),metric=sak.signal.abs_max) for k in  ST}\n",
    "T   = {k: sak.data.ball_scaling(sak.signal.on_off_correction(smooth(  T[k],window)),metric=sak.signal.abs_max) for k in   T}\n",
    "TP  = {k: sak.data.ball_scaling(sak.signal.on_off_correction(smooth( TP[k],window)),metric=sak.signal.abs_max) for k in  TP}\n",
    "\n",
    "\n",
    "##### 3. Load QTDB #####\n",
    "dataset             = pd.read_csv(os.path.join(input_files,'QTDB','Dataset.csv'), index_col=0)\n",
    "dataset             = dataset.sort_index(axis=1)\n",
    "labels              = np.asarray(list(dataset)) # In case no data augmentation is applied\n",
    "description         = dataset.describe()\n",
    "group               = {k: '_'.join(k.split('_')[:-1]) for k in dataset}\n",
    "unique_ids          = list(set([k.split('_')[0] for k in dataset]))\n",
    "\n",
    "# Load validity\n",
    "validity            = sak.load_data(os.path.join(input_files,'QTDB','validity.csv'))\n",
    "\n",
    "# Load fiducials\n",
    "Pon_QTDB            = sak.load_data(os.path.join(input_files,'QTDB','PonNew.csv'))\n",
    "Poff_QTDB           = sak.load_data(os.path.join(input_files,'QTDB','PoffNew.csv'))\n",
    "QRSon_QTDB          = sak.load_data(os.path.join(input_files,'QTDB','QRSonNew.csv'))\n",
    "QRSoff_QTDB         = sak.load_data(os.path.join(input_files,'QTDB','QRSoffNew.csv'))\n",
    "Ton_QTDB            = sak.load_data(os.path.join(input_files,'QTDB','TonNew.csv'))\n",
    "Toff_QTDB           = sak.load_data(os.path.join(input_files,'QTDB','ToffNew.csv'))\n",
    "\n",
    "# Generate masks & signals\n",
    "signal_QTDB = {}\n",
    "segmentation_QTDB = {}\n",
    "for k in tqdm.tqdm(QRSon_QTDB):\n",
    "    # Check file exists and all that\n",
    "    if k not in validity:\n",
    "        print(\"Issue with file {}, continuing...\".format(k))\n",
    "        continue\n",
    "\n",
    "    # Store signal\n",
    "    signal = dataset[k][validity[k][0]:validity[k][1]].values\n",
    "    signal = sak.signal.on_off_correction(signal)\n",
    "    amplitude = np.median(sak.signal.moving_lambda(signal,200,sak.signal.abs_max))\n",
    "    signal = signal/amplitude\n",
    "    signal_QTDB[k] = signal[None,]\n",
    "\n",
    "    # Generate boolean mask\n",
    "    segmentation = np.zeros((3,dataset.shape[0]),dtype=bool)\n",
    "    if k in Pon_QTDB:\n",
    "        for on,off in zip(Pon_QTDB[k],Poff_QTDB[k]):\n",
    "            segmentation[0,on:off] = True\n",
    "    if k in QRSon_QTDB:\n",
    "        for on,off in zip(QRSon_QTDB[k],QRSoff_QTDB[k]):\n",
    "            segmentation[1,on:off] = True\n",
    "    if k in Ton_QTDB:\n",
    "        for on,off in zip(Ton_QTDB[k],Toff_QTDB[k]):\n",
    "            segmentation[2,on:off] = True\n",
    "\n",
    "    segmentation_QTDB[k] = segmentation[:,validity[k][0]:validity[k][1]]\n",
    "\n",
    "\n",
    "##### 4. Generate random splits #####\n",
    "# 4.1. Split into train and test\n",
    "all_keys_synthetic = {}\n",
    "for k in list(P) + list(PQ) + list(QRS) + list(ST) + list(T) + list(TP):\n",
    "    uid = k.split(\"###\")[0].split(\"_\")[0].split(\"-\")[0]\n",
    "    if uid not in all_keys_synthetic:\n",
    "        all_keys_synthetic[uid] = [k]\n",
    "    else:\n",
    "        all_keys_synthetic[uid].append(k)\n",
    "\n",
    "all_keys_real = {}\n",
    "for k in list(signal_QTDB) + list(segmentation_QTDB):\n",
    "    uid = k.split(\"###\")[0].split(\"_\")[0].split(\"-\")[0]\n",
    "    if uid not in all_keys_real:\n",
    "        all_keys_real[uid] = [k]\n",
    "    else:\n",
    "        all_keys_real[uid].append(k)\n",
    "\n",
    "# 4.2. Get database and file\n",
    "filenames = []\n",
    "database = []\n",
    "for k in all_keys_synthetic:\n",
    "    filenames.append(k)\n",
    "    if k.startswith(\"SOO\"):\n",
    "        database.append(0)\n",
    "    elif k.startswith(\"sel\"):\n",
    "        database.append(1)\n",
    "    else:\n",
    "        database.append(2)\n",
    "filenames = np.array(filenames)\n",
    "database = np.array(database)\n",
    "\n",
    "# Set random seed for the execution and perform train/test splitting\n",
    "random.seed(execution[\"seed\"])\n",
    "np.random.seed(execution[\"seed\"])\n",
    "torch.random.manual_seed(execution[\"seed\"])\n",
    "splitter = sklearn.model_selection.StratifiedKFold(5).split(filenames,database)\n",
    "splits = list(splitter)\n",
    "indices_train = [s[0] for s in splits]\n",
    "indices_valid = [s[1] for s in splits]\n",
    "\n",
    "##### 5. Train folds #####\n",
    "# 5.1. Save model-generating files\n",
    "target_path = execution[\"save_directory\"] # Store original output path for future usage\n",
    "original_length = execution[\"dataset\"][\"length\"]\n",
    "if not os.path.isdir(os.path.join(target_path,model_name)):\n",
    "    pathlib.Path(os.path.join(target_path,model_name)).mkdir(parents=True, exist_ok=True)\n",
    "# shutil.copyfile(\"./train_multi.py\",os.path.join(target_path,model_name,\"train_multi.py\"))\n",
    "shutil.copyfile(\"./src/data.py\",os.path.join(target_path,model_name,\"data.py\"))\n",
    "shutil.copyfile(\"./src/metrics.py\",os.path.join(target_path,model_name,\"metrics.py\"))\n",
    "# shutil.copyfile(\"./sak/torch/nn/modules/loss.py\",os.path.join(target_path,model_name,\"loss.py\"))\n",
    "shutil.copyfile(config_file,os.path.join(target_path,model_name,os.path.split(config_file)[1]))\n",
    "\n",
    "# 5.2. Save folds of valid files\n",
    "all_folds_test = {\"fold_{}\".format(i+1): np.array(filenames)[ix_valid] for i,ix_valid in enumerate(indices_valid)}\n",
    "sak.save_data(all_folds_test,os.path.join(target_path,model_name,\"validation_files.csv\"))\n",
    "\n",
    "# 5.3. Iterate over folds\n",
    "for i,(ix_train,ix_valid) in enumerate(zip(indices_train,indices_valid)):\n",
    "    print(\"################# FOLD {} #################\".format(i+1))\n",
    "    # Synthetic keys\n",
    "    train_keys_synthetic, valid_keys_synthetic = ([],[])\n",
    "    for k in np.array(filenames)[ix_train]: \n",
    "        train_keys_synthetic += all_keys_synthetic[k]\n",
    "    for k in np.array(filenames)[ix_valid]: \n",
    "        valid_keys_synthetic += all_keys_synthetic[k]\n",
    "\n",
    "    # Real keys\n",
    "    train_keys_real, valid_keys_real = ([],[])\n",
    "    for k in np.array(filenames)[ix_train]: \n",
    "        if k in all_keys_real: train_keys_real += all_keys_real[k]\n",
    "    for k in np.array(filenames)[ix_valid]: \n",
    "        if k in all_keys_real: valid_keys_real += all_keys_real[k]\n",
    "\n",
    "    # Avoid repetitions\n",
    "    train_keys_synthetic = list(set(train_keys_synthetic))\n",
    "    valid_keys_synthetic = list(set(valid_keys_synthetic))\n",
    "    train_keys_real = list(set(train_keys_real))\n",
    "    valid_keys_real = list(set(valid_keys_real))\n",
    "\n",
    "    # ~~~~~~~~~~~~~~~~~~~~ Refine synthetic set ~~~~~~~~~~~~~~~~~~~~\n",
    "    # Divide train/valid segments\n",
    "    Ptrain   = {k:   P[k] for k in   P if k in train_keys_synthetic}\n",
    "    PQtrain  = {k:  PQ[k] for k in  PQ if k in train_keys_synthetic}\n",
    "    QRStrain = {k: QRS[k] for k in QRS if k in train_keys_synthetic}\n",
    "    STtrain  = {k:  ST[k] for k in  ST if k in train_keys_synthetic}\n",
    "    Ttrain   = {k:   T[k] for k in   T if k in train_keys_synthetic}\n",
    "    TPtrain  = {k:  TP[k] for k in  TP if k in train_keys_synthetic}\n",
    "\n",
    "    Pvalid   = {k:   P[k] for k in   P if k in valid_keys_synthetic}\n",
    "    PQvalid  = {k:  PQ[k] for k in  PQ if k in valid_keys_synthetic}\n",
    "    QRSvalid = {k: QRS[k] for k in QRS if k in valid_keys_synthetic}\n",
    "    STvalid  = {k:  ST[k] for k in  ST if k in valid_keys_synthetic}\n",
    "    Tvalid   = {k:   T[k] for k in   T if k in valid_keys_synthetic}\n",
    "    TPvalid  = {k:  TP[k] for k in  TP if k in valid_keys_synthetic}\n",
    "\n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~ Refine real set ~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    signal_QTDB_train       = {k:       signal_QTDB[k] for k in       signal_QTDB if k in train_keys_real}\n",
    "    signal_QTDB_valid       = {k:       signal_QTDB[k] for k in       signal_QTDB if k in valid_keys_real}\n",
    "    segmentation_QTDB_train = {k: segmentation_QTDB[k] for k in segmentation_QTDB if k in train_keys_real}\n",
    "    segmentation_QTDB_valid = {k: segmentation_QTDB[k] for k in segmentation_QTDB if k in valid_keys_real}\n",
    "\n",
    "\n",
    "    # Prepare folders\n",
    "    execution[\"save_directory\"] = os.path.join(target_path, model_name, \"fold_{}\".format(i+1))\n",
    "    if not os.path.isdir(execution[\"save_directory\"]):\n",
    "        pathlib.Path(execution[\"save_directory\"]).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Define synthetic datasets\n",
    "    dataset_train_synthetic = src.data.Dataset(Ptrain, QRStrain, Ttrain, PQtrain, STtrain, TPtrain, \n",
    "                                               Pdistribution, QRSdistribution, Tdistribution, PQdistribution, \n",
    "                                               STdistribution, TPdistribution, **execution[\"dataset\"])\n",
    "    execution[\"dataset\"][\"length\"] = execution[\"dataset\"][\"length\"]//4 # On synthetic data, not so useful to do intensive validation\n",
    "    dataset_valid_synthetic = src.data.Dataset(Pvalid, QRSvalid, Tvalid, PQvalid, STvalid, TPvalid, \n",
    "                                               Pdistribution, QRSdistribution, Tdistribution, PQdistribution, \n",
    "                                               STdistribution, TPdistribution, **execution[\"dataset\"])\n",
    "    execution[\"dataset\"][\"length\"] = original_length # On synthetic data, not so useful to do intensive validation\n",
    "\n",
    "    # Define real datasets\n",
    "    dataset_train_real = src.data.DatasetQTDB(signal_QTDB_train,segmentation_QTDB_train,execution[\"dataset\"][\"N\"],128)\n",
    "    dataset_valid_real = src.data.DatasetQTDB(signal_QTDB_valid,segmentation_QTDB_valid,execution[\"dataset\"][\"N\"],128)\n",
    "\n",
    "    # Define merging dataset\n",
    "    dataset_train = sak.torch.data.UniformMultiDataset((dataset_train_synthetic,dataset_train_real),[10,1],[1,10],return_weights=True)\n",
    "    sampler_train = sak.torch.data.UniformMultiSampler(dataset_train)\n",
    "    dataset_valid = sak.torch.data.UniformMultiDataset((dataset_valid_synthetic,dataset_valid_real),[10,1],[1,10],return_weights=True)\n",
    "    sampler_valid = sak.torch.data.UniformMultiSampler(dataset_valid)\n",
    "\n",
    "    # Create dataloaders\n",
    "    loader_train = torch.utils.data.DataLoader(dataset_train, sampler=sampler_train, **execution[\"loader\"])\n",
    "    loader_valid = torch.utils.data.DataLoader(dataset_valid, sampler=sampler_valid, **execution[\"loader\"])\n",
    "\n",
    "    # Define model\n",
    "    model = sak.from_dict(execution[\"model\"]).float().cuda()\n",
    "\n",
    "    # Train model\n",
    "    state = {\n",
    "        \"epoch\"         : 0,\n",
    "        \"device\"        : torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "        \"optimizer\"     : sak.class_selector(execution[\"optimizer\"][\"class\"])(model.parameters(), **execution[\"optimizer\"][\"arguments\"]),\n",
    "        \"root_dir\"      : \"./\"\n",
    "    }\n",
    "    if \"scheduler\" in execution:\n",
    "        state[\"scheduler\"] = sak.class_selector(execution[\"scheduler\"][\"class\"])(state[\"optimizer\"], **execution[\"scheduler\"][\"arguments\"])\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1135 [00:01<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for inputs in tqdm.tqdm(loader_train):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_ssl(loader_labeled,loader_unlabeled):\n",
    "    # Set up all stuff\n",
    "    counter_labeled,counter_unlabeled =                    0,                      0\n",
    "    length_labeled,length_unlabeled   =  len(loader_labeled),  len(loader_unlabeled)\n",
    "    iter_labeled,    iter_unlabeled   = iter(loader_labeled), iter(loader_unlabeled)\n",
    "    maxlen                            =  max(length_labeled,       length_unlabeled)\n",
    "    \n",
    "    # Get examples\n",
    "    for _ in range(maxlen):\n",
    "        if counter_labeled   == length_labeled:\n",
    "            iter_labeled   = iter(loader_labeled)\n",
    "        if counter_unlabeled == length_unlabeled:\n",
    "            iter_unlabeled = iter(loader_unlabeled)\n",
    "        counter_labeled   += 1\n",
    "        counter_unlabeled += 1\n",
    "\n",
    "        # Return next element in iterator\n",
    "        yield (next(iter_labeled), next(iter_unlabeled))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetUnsupervised(torch.utils.data.Dataset):\n",
    "    '''Unsupervised dataset'''\n",
    "\n",
    "    def __init__(self, file: str, window: int, N_per_db: int = None, dtype='float32'):\n",
    "        '''Initialization'''\n",
    "        # Store inputs\n",
    "        self.file              = file\n",
    "        self.fhandle           = pathlib.Path(self.file).open('rb')\n",
    "        self.reader            = fleetfmt.FileReader(self.fhandle)\n",
    "        self.keys              = list(self.reader.keys())\n",
    "        self.window            = window\n",
    "        self.dtype             = dtype\n",
    "        self.N_per_db          = N_per_db\n",
    "            \n",
    "        if (self.N_per_db is not None):\n",
    "            self.databases         = []\n",
    "            self.N_databases       = {}\n",
    "            self.key_per_database  = {}\n",
    "            for k in self.keys:\n",
    "                DB = k.split(\"/\")[0]\n",
    "                if DB not in self.N_databases:\n",
    "                    self.databases.append(DB)\n",
    "                    self.N_databases[DB] = 0\n",
    "                    self.key_per_database[DB] = []\n",
    "                self.N_databases[DB] += 1\n",
    "                self.key_per_database[DB].append(k)\n",
    "            self.len           = self.N_per_db*len(self.N_databases)\n",
    "            self.__getkey      = self.__get_key_oversampling\n",
    "            self.max_N             = max([self.N_databases[k] for k in self.N_databases])\n",
    "        else:\n",
    "            self.len           = len(self.keys)\n",
    "            self.__getkey      = self.__get_key_all\n",
    "\n",
    "    def __len__(self):\n",
    "        '''Denotes the number of batches per epoch'''\n",
    "        return self.len\n",
    "    \n",
    "    def __get_key_oversampling(self, i):\n",
    "        db = self.databases[i//self.N_per_db]\n",
    "        return random.choice(self.key_per_database[db])\n",
    "    \n",
    "    def __get_key_all(self, i):\n",
    "        return self.keys[i]\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        # Get key\n",
    "        key = self.__getkey(i)\n",
    "        \n",
    "        # Read fragment\n",
    "        fragment = self.reader.read(key)\n",
    "        \n",
    "        # Generate onset randomly\n",
    "        onset = random.randint(0,fragment.size-self.window)\n",
    "        \n",
    "        # Return fragment\n",
    "        return {\"x\": fragment[onset:onset+self.window].astype(self.dtype)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = DatasetUnsupervised(\"/media/guille/DADES/DADES/ECG/unsupervised_float32_250hz.fleet\",2048,N_per_db=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(self)):\n",
    "    self[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f30429dd5b0>]"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = random.randint(0,len(self)-1)\n",
    "x = self[i][\"x\"]\n",
    "plt.plot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_ssl(loader_labeled,loader_unlabeled):\n",
    "    # Set up all stuff\n",
    "    counter_labeled,counter_unlabeled =                    0,                      0\n",
    "    length_labeled,length_unlabeled   =  len(loader_labeled),  len(loader_unlabeled)\n",
    "    iter_labeled,    iter_unlabeled   = iter(loader_labeled), iter(loader_unlabeled)\n",
    "    maxlen                            =  max(length_labeled,       length_unlabeled)\n",
    "    \n",
    "    # Get examples\n",
    "    for _ in range(maxlen):\n",
    "        if counter_labeled   == length_labeled:\n",
    "            iter_labeled   = iter(loader_labeled)\n",
    "        if counter_unlabeled == length_unlabeled:\n",
    "            iter_unlabeled = iter(loader_unlabeled)\n",
    "        counter_labeled   += 1\n",
    "        counter_unlabeled += 1\n",
    "\n",
    "        # Return next element in iterator\n",
    "        yield (next(iter_labeled), next(iter_unlabeled))\n",
    "\n",
    "def do_epoch_ssl(model: torch.nn.Module, state: dict, config: dict, \n",
    "                 dataloader_labeled:   torch.utils.data.DataLoader, \n",
    "                 dataloader_unlabeled: torch.utils.data.DataLoader, \n",
    "                 criterion: Callable, \n",
    "                 criterion_crossentropy: Callable) -> list:\n",
    "    \"\"\"\n",
    "    Minimum do_epoch example\n",
    "    1. Select device to send tensors\n",
    "    2. Initialize loss function\n",
    "    3. Predict + optimize batch\n",
    "    4. Save loss per batch (useful given size of dataset)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Record progress\n",
    "    max_length = max(len(dataloader_labeled),len(dataloader_unlabeled))\n",
    "    batch_loss = np.zeros((max_length,),dtype='float16')\n",
    "\n",
    "    # Create transforms\n",
    "    if ('data_pre' in config):\n",
    "        data_pre     = sak.from_dict(config[\"data_pre\"])\n",
    "    if ('augmentation' in config) and model.training:\n",
    "        augmentation = sak.from_dict(config[\"augmentation\"])\n",
    "    if ('data_post' in config):\n",
    "        data_post    = sak.from_dict(config[\"data_post\"])\n",
    "\n",
    "    # Select iterator decorator\n",
    "    train_type = 'Train' if model.training else 'Valid'\n",
    "    iterator = sak.get_tqdm(dataloader, config.get('iterator',''), \n",
    "                            desc=\"({}) Epoch {:>3d}/{:>3d}, Loss {:0.3f}\".format(train_type, \n",
    "                                                                                 state['epoch']+1, \n",
    "                                                                                 config['epochs'], np.inf))\n",
    "\n",
    "    # Iterate over all data in train/validation/test dataloader:\n",
    "    print_loss = np.inf\n",
    "    for i, inputs in enumerate(iterator):\n",
    "        # Apply data transforms\n",
    "        if ('data_pre' in config):\n",
    "            data_pre(inputs=inputs)\n",
    "        if ('augmentation' in config) and model.training:\n",
    "            augmentation(inputs=inputs)\n",
    "        if ('data_post' in config):\n",
    "            data_post(inputs=inputs)\n",
    "\n",
    "        # Map all inputs to device\n",
    "        for k in inputs:\n",
    "            inputs[k] = inputs[k].to(state['device'], non_blocking=True)\n",
    "\n",
    "        # Set gradient to zero\n",
    "        if model.training: \n",
    "            state['optimizer'].zero_grad()\n",
    "\n",
    "        # Predict input data\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(inputs=inputs,outputs=outputs,state=state)\n",
    "\n",
    "        # Break early\n",
    "        if torch.isnan(loss):\n",
    "            raise ValueError(\"Nan loss value encountered. Stopping...\")\n",
    "\n",
    "        # Retrieve for printing purposes\n",
    "        print_loss = loss.item()\n",
    "        \n",
    "        # Optimize network's weights\n",
    "        if model.training:\n",
    "            loss.backward()\n",
    "            state['optimizer'].step()\n",
    "\n",
    "        # Accumulate losses\n",
    "        batch_loss[i] = print_loss\n",
    "\n",
    "        # Change iterator description\n",
    "        if isinstance(iterator,tqdm.tqdm):\n",
    "            if i == len(iterator)-1:\n",
    "                iterator.set_description(\"({}) Epoch {:>3d}/{:>3d}, Loss {:10.3f}\".format(train_type, state['epoch']+1, config['epochs'], np.mean(batch_loss)))\n",
    "            else:\n",
    "                iterator.set_description(\"({}) Epoch {:>3d}/{:>3d}, Loss {:10.3f}\".format(train_type, state['epoch']+1, config['epochs'], print_loss))\n",
    "            iterator.refresh()\n",
    "\n",
    "    return batch_loss\n",
    "\n",
    "\n",
    "def train_model_ssl(model, state: dict, config: dict, loader: torch.utils.data.DataLoader):\n",
    "    # Send model to device\n",
    "    model = model.to(state['device'])\n",
    "\n",
    "    # Instantiate criterion\n",
    "    criterion = sak.from_dict(config['loss'])\n",
    "    \n",
    "    # Initialize best loss for early stopping\n",
    "    if 'best_loss' not in state:\n",
    "        state['best_loss'] = np.inf\n",
    "\n",
    "    # Get savedir string\n",
    "    if \"savedir\" in config:          str_savedir = 'savedir'\n",
    "    elif \"save_directory\" in config: str_savedir = 'save_directory'\n",
    "    else: raise ValueError(\"Configuration file should include either the 'savedir' or 'save_directory' fields [case-sensitive]\")\n",
    "\n",
    "    # Iterate over epochs\n",
    "    for epoch in range(state['epoch'], config['epochs']):\n",
    "        try:\n",
    "            # Store current epoch\n",
    "            state['epoch'] = epoch\n",
    "            \n",
    "            # Train model\n",
    "            loss_train = do_epoch(model.train(), state, config, loader, criterion)\n",
    "            state['loss_train'] = np.mean(loss_train)\n",
    "\n",
    "            # Save model/state info\n",
    "            model = model.cpu().eval()\n",
    "            torch.save(model,              os.path.join(config[str_savedir],'checkpoint.model'),      pickle_module=dill)\n",
    "            torch.save(model.state_dict(), os.path.join(config[str_savedir],'checkpoint.state_dict'), pickle_module=dill)\n",
    "            sak.pickledump(state, os.path.join(config[str_savedir],'checkpoint.state'), mode='wb')\n",
    "            model = model.to(state['device'])\n",
    "            \n",
    "            # Log train loss\n",
    "            with open(os.path.join(config[str_savedir],'log.csv'),'a') as f:\n",
    "                csvwriter = csv.writer(f)\n",
    "                csvwriter.writerow([\"(Train) Epoch {:>3d}/{:>3d}, Loss {:10.3f}, Time {}\".format(state['epoch']+1, config['epochs'], state['loss_train'], time.ctime())])\n",
    "\n",
    "            # Check if loss is best loss\n",
    "            if state['loss_train'] < state['best_loss']:\n",
    "                state['best_loss'] = state['loss_train']\n",
    "                state['best_epoch'] = epoch\n",
    "                \n",
    "                # Copy checkpoint and mark as best\n",
    "                shutil.copyfile(os.path.join(config[str_savedir],'checkpoint.model'), os.path.join(config[str_savedir],'model_best.model'))\n",
    "                shutil.copyfile(os.path.join(config[str_savedir],'checkpoint.state'), os.path.join(config[str_savedir],'model_best.state'))\n",
    "        except KeyboardInterrupt:\n",
    "            model = model.cpu().eval()\n",
    "            torch.save(model,              os.path.join(config[str_savedir],'keyboard_interrupt.model'),      pickle_module=dill)\n",
    "            torch.save(model.state_dict(), os.path.join(config[str_savedir],'keyboard_interrupt.state_dict'), pickle_module=dill)\n",
    "            sak.pickledump(state, os.path.join(config[str_savedir],'keyboard_interrupt.state'), mode='wb')\n",
    "            raise\n",
    "        except:\n",
    "            model = model.cpu().eval()\n",
    "            torch.save(model,              os.path.join(config[str_savedir],'error.model'),      pickle_module=dill)\n",
    "            torch.save(model.state_dict(), os.path.join(config[str_savedir],'error.state_dict'), pickle_module=dill)\n",
    "            sak.pickledump(state, os.path.join(config[str_savedir],'error.state'), mode='wb')\n",
    "            raise\n",
    "\n",
    "\n",
    "def train_valid_model_ssl(model, state: dict, config: dict, \n",
    "                          loader_train: torch.utils.data.DataLoader, \n",
    "                          loader_valid: torch.utils.data.DataLoader):\n",
    "    # Send model to device\n",
    "    model = model.to(state['device'])\n",
    "\n",
    "    # Instantiate criterion\n",
    "    criterion = sak.from_dict(config['loss'])\n",
    "    \n",
    "    # Initialize best loss for early stopping\n",
    "    if 'best_loss' not in state:\n",
    "        state['best_loss'] = np.inf\n",
    "\n",
    "    # Get savedir string\n",
    "    if \"savedir\" in config:          str_savedir = 'savedir'\n",
    "    elif \"save_directory\" in config: str_savedir = 'save_directory'\n",
    "    else: raise ValueError(\"Configuration file should include either the 'savedir' or 'save_directory' fields [case-sensitive]\")\n",
    "\n",
    "    # Iterate over epochs\n",
    "    for epoch in range(state['epoch'], config['epochs']):\n",
    "        try:\n",
    "            # Store current epoch\n",
    "            state['epoch'] = epoch\n",
    "            \n",
    "            # Training model\n",
    "            loss_train = do_epoch(model.train(), state, config, loader_train, criterion)\n",
    "            state['loss_train'] = np.mean(loss_train)\n",
    "\n",
    "            # Validate results\n",
    "            with torch.no_grad():\n",
    "                loss_valid = do_epoch(model.eval(), state, config, loader_valid, criterion)\n",
    "            state['loss_validation'] = np.mean(loss_valid)\n",
    "\n",
    "            # Update learning rate scheduler\n",
    "            if 'scheduler' in state:\n",
    "                state['scheduler'].step(state['loss_validation'])\n",
    "\n",
    "            # Save model/state info\n",
    "            model = model.cpu().eval()\n",
    "            torch.save(model,              os.path.join(config[str_savedir],'checkpoint.model'),      pickle_module=dill)\n",
    "            torch.save(model.state_dict(), os.path.join(config[str_savedir],'checkpoint.state_dict'), pickle_module=dill)\n",
    "            sak.pickledump(state, os.path.join(config[str_savedir],'checkpoint.state'), mode='wb')\n",
    "            model = model.to(state['device'])\n",
    "            \n",
    "            # Log train/valid losses\n",
    "            with open(os.path.join(config[str_savedir],'log.csv'),'a') as f:\n",
    "                csvwriter = csv.writer(f)\n",
    "                csvwriter.writerow([\"(Train) Epoch {:>3d}/{:>3d}, Loss {:10.3f}, Time {}\".format(state['epoch']+1, config['epochs'], state['loss_train'], time.ctime())])\n",
    "                csvwriter.writerow([\"(Valid) Epoch {:>3d}/{:>3d}, Loss {:10.3f}, Time {}\".format(state['epoch']+1, config['epochs'], state['loss_validation'], time.ctime())])\n",
    "\n",
    "            # Check if loss is best loss\n",
    "            compound_loss = 2*state['loss_train']*state['loss_validation']/(state['loss_train']+state['loss_validation'])\n",
    "            if compound_loss < state['best_loss']:\n",
    "                state['best_loss'] = compound_loss\n",
    "                state['best_epoch'] = epoch\n",
    "                \n",
    "                # Copy checkpoint and mark as best\n",
    "                shutil.copyfile(os.path.join(config[str_savedir],'checkpoint.model'), os.path.join(config[str_savedir],'model_best.model'))\n",
    "                shutil.copyfile(os.path.join(config[str_savedir],'checkpoint.state'), os.path.join(config[str_savedir],'model_best.state'))\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            model = model.cpu().eval()\n",
    "            torch.save(model,              os.path.join(config[str_savedir],'keyboard_interrupt.model'),      pickle_module=dill)\n",
    "            torch.save(model.state_dict(), os.path.join(config[str_savedir],'keyboard_interrupt.state_dict'), pickle_module=dill)\n",
    "            sak.pickledump(state, os.path.join(config[str_savedir],'keyboard_interrupt.state'), mode='wb')\n",
    "            raise\n",
    "        except:\n",
    "            model = model.cpu().eval()\n",
    "            torch.save(model,              os.path.join(config[str_savedir],'error.model'),      pickle_module=dill)\n",
    "            torch.save(model.state_dict(), os.path.join(config[str_savedir],'error.state_dict'), pickle_module=dill)\n",
    "            sak.pickledump(state, os.path.join(config[str_savedir],'error.state'), mode='wb')\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I/O FILES\n",
    "\n",
    "    aaa = pd.DataFrame(np.random.rand(10000,10000))\n",
    "    \n",
    "    ~~~ FEATHER ~~~\n",
    "    767M\ttest.fth\n",
    "    299 ms ± 21 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "\n",
    "    ~~~ HDF5 ~~~\n",
    "    764M\ttest.hdf5\n",
    "    451 ms ± 92.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "\n",
    "    ~~~ CSV ~~~\n",
    "    1,8G\ttest.csv\n",
    "    29 s ± 291 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "\n",
    "    ~~~ WFDN ~~~\n",
    "    382M\ttest.dat\n",
    "    732K\ttest.hea\n",
    "    3.96 s ± 198 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "\n",
    "    ~~~ FLEET ~~~\n",
    "    771M\ttest.fleet # With pyarrow\n",
    "    765M\ttest.fleet # With pickle protocol 5\n",
    "    # 315 ms ± 10.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) # With pyarrow\n",
    "    161 ms ± 446 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)  # With pickle protocol 5\n",
    "\n",
    "    https://towardsdatascience.com/what-format-should-i-store-my-ecg-data-in-for-dl-training-bc808eb64981"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing numpy content to a new Fleet file.\n",
      "Done.\n",
      "766M\ttest.fleet\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import fleetfmt\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import random\n",
    "import skimage\n",
    "import skimage.util\n",
    "\n",
    "aaa = np.random.rand(10000,10000)\n",
    "print(\"Writing numpy content to a new Fleet file.\")\n",
    "with pathlib.Path(\"test.fleet\").open('wb') as fhandle, fleetfmt.FileWriter(fhandle) as writer:\n",
    "    for i,value in enumerate(aaa):\n",
    "        writer.append(f\"jakhgkjahgkjhak {i}\", value)\n",
    "print(\"Done.\")\n",
    "!du -sh test.fleet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162 ms ± 381 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "with pathlib.Path(\"test.fleet\").open('rb') as fhandle, fleetfmt.FileReader(fhandle) as reader:\n",
    "    # get keys\n",
    "    dkeys = list(reader.keys())\n",
    "\n",
    "    # get values\n",
    "    for key in dkeys:\n",
    "        value = reader.read(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279 ns ± 1.02 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n",
      "18.4 µs ± 27.2 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "with pathlib.Path(\"test.fleet\").open('rb') as fhandle, fleetfmt.FileReader(fhandle) as reader:\n",
    "    # get keys\n",
    "    dkeys = list(reader.keys())\n",
    "\n",
    "    # get random value\n",
    "    %timeit key = random.choice(dkeys)\n",
    "    %timeit key = random.choice(dkeys); reader.read(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST I/O FORMAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing numpy content to a new Fleet file.\n",
      "MUSE dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10646/10646 [01:45<00:00, 100.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brugada dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [01:24<00:00, 12.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fallot dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1941/1941 [00:17<00:00, 112.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HCM dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153/153 [00:00<00:00, 171.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Challenge dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41704/41704 [05:48<00:00, 119.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LongQT dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 807/807 [00:07<00:00, 109.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THEW dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1700/1700 [2:58:24<00:00,  6.30s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepFake dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150000/150000 [12:54<00:00, 193.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SoO dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 541/541 [00:30<00:00, 17.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDB dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [00:27<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVDB dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:05<00:00, 15.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictAF dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [06:30<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zhejiang dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 336/336 [00:08<00:00, 39.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HUVR_CARTO dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20618/20618 [37:29<00:00,  9.17it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "116G\t/media/guille/DADES/DADES/ECG/unsupervised.fleet\n"
     ]
    }
   ],
   "source": [
    "import ishneholterlib\n",
    "import struct\n",
    "\n",
    "window = 2048\n",
    "max_size = window*10\n",
    "window_step = max_size-window//4\n",
    "target_fs = 250\n",
    "target_dtype = \"float32\"\n",
    "\n",
    "print(\"Writing numpy content to a new Fleet file.\")\n",
    "with pathlib.Path(f\"/media/guille/DADES/DADES/ECG/unsupervised_{target_dtype}.fleet\").open('wb') as fhandle, fleetfmt.FileWriter(fhandle) as writer:\n",
    "    print(\"MUSE dataset\")\n",
    "    time.sleep(0.5)\n",
    "    all_files = glob.glob(\"/home/guille/DADES/DADES/ECG/ECGData/*.csv\")\n",
    "    for file in tqdm.tqdm(all_files):\n",
    "        try:\n",
    "            root,fname,ext = sak.splitrfe(file)\n",
    "            tmp = pd.read_csv(file)\n",
    "            tmp = tmp.round(3)\n",
    "            tmp.columns = map(lambda x: str(x).upper(), tmp.columns)\n",
    "            fs = 500\n",
    "            hea = list(tmp.columns)\n",
    "            tmp = sak.signal.interpolate.interp1d(tmp.values,target_fs*tmp.shape[0]//fs,axis=0).T\n",
    "            for k,value in zip(hea,tmp): \n",
    "                if value.size < window: continue\n",
    "                writer.append(f\"MUSE/{fname[5:]}/{k}###0\", value.astype(target_dtype))\n",
    "        except KeyboardInterrupt:\n",
    "            raise\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    print(\"Brugada dataset\")\n",
    "    time.sleep(0.5)\n",
    "    all_files = glob.glob(\"/home/guille/DADES/DADES/ECG/Brugada/Databases/HUVR/*.ecg\")\n",
    "    for file in tqdm.tqdm(all_files):\n",
    "        try:\n",
    "            root,fname,ext = sak.splitrfe(file)\n",
    "            ecg = ishneholterlib.Holter(file)\n",
    "            ecg.load_data()\n",
    "            fs = ecg.sr\n",
    "            for lead in ecg.lead:\n",
    "                k = lead.spec_str().upper()\n",
    "                data = lead.data.copy()\n",
    "                data = sak.signal.interpolate.interp1d(data,target_fs*data.size//fs)\n",
    "                if data.size > max_size:\n",
    "                    data = skimage.util.view_as_windows(data,(max_size,),step=window_step)\n",
    "                else:\n",
    "                    data = data[None,]\n",
    "                for i,value in enumerate(data):\n",
    "                    if i == 0:\n",
    "                        continue\n",
    "                    if value.size < window: continue\n",
    "                    writer.append(f\"Brugada/{fname}/{k}###{i}\", value.astype(target_dtype))\n",
    "        except KeyboardInterrupt:\n",
    "            raise\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    print(\"Fallot dataset\")\n",
    "    time.sleep(0.5)\n",
    "    all_files = glob.glob(\"/home/guille/DADES/DADES/ECG/Fallot/ECGs/*.csv\")\n",
    "    for file in tqdm.tqdm(all_files):\n",
    "        try:\n",
    "            root,fname,ext = sak.splitrfe(file)\n",
    "            tmp = pd.read_csv(file)\n",
    "            tmp = tmp.round(3)\n",
    "            tmp.columns = map(lambda x: str(x).upper(), tmp.columns)\n",
    "            hea = map(lambda x: str(x).upper(), tmp.columns)\n",
    "            fs = 1/np.unique(np.round(np.diff(tmp[\"TIME IN SEC.\"].values),5))\n",
    "            assert fs.size == 1, \"check fs!!!\"\n",
    "            fs = int(fs[0])\n",
    "            hea = list(tmp.columns)\n",
    "            tmp = sak.signal.interpolate.interp1d(tmp.values,target_fs*tmp.shape[0]//fs,axis=0).T\n",
    "            for k,value in zip(hea,tmp): \n",
    "                if k == \"TIME IN SEC.\": continue\n",
    "                if value.size < window: continue\n",
    "                writer.append(f\"Fallot/{fname}/{k}###0\", value.astype(target_dtype))\n",
    "        except KeyboardInterrupt:\n",
    "            raise\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    print(\"HCM dataset\")\n",
    "    time.sleep(0.5)\n",
    "    all_files = glob.glob(\"/home/guille/DADES/DADES/ECG/HCMData/CSV/*.csv\")\n",
    "    for file in tqdm.tqdm(all_files):\n",
    "        try:\n",
    "            root,fname,ext = sak.splitrfe(file)\n",
    "            tmp = pd.read_csv(file,header=None)[:-500]/1000\n",
    "            tmp.columns = map(lambda x: str(x).upper(), StandardHeader)\n",
    "            fs = 500\n",
    "            tmp = sak.signal.interpolate.interp1d(tmp.values,target_fs*tmp.shape[0]//fs,axis=0).T\n",
    "            for k,value in zip(StandardHeader,tmp): \n",
    "                if value.size < window: continue\n",
    "                writer.append(f\"HCM/{fname}/{k}###0\", value.astype(target_dtype))\n",
    "        except KeyboardInterrupt:\n",
    "            raise\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    print(\"Challenge dataset\")\n",
    "    time.sleep(0.5)\n",
    "    all_files = glob.glob(\"/home/guille/DADES/DADES/ECG/Challenge/*.mat\")\n",
    "    for file in tqdm.tqdm(all_files):\n",
    "        try:\n",
    "            root,fname,ext = sak.splitrfe(file)\n",
    "            sig,hea = wfdb.rdsamp(os.path.join(root,fname),return_res=16)\n",
    "            hea[\"sig_name\"] = list(map(lambda x: str(x).upper(), hea[\"sig_name\"]))\n",
    "            fs = hea[\"fs\"]\n",
    "            sig = sak.signal.interpolate.interp1d(sig,target_fs*sig.shape[0]//fs,axis=0).T\n",
    "            for k,lead in zip(hea[\"sig_name\"],sig):\n",
    "                if lead.size > max_size:\n",
    "                    data = skimage.util.view_as_windows(lead,(max_size,),step=window_step)\n",
    "                else:\n",
    "                    data = lead[None,]\n",
    "                for i,value in enumerate(data):\n",
    "                    if value.size < window: continue\n",
    "                    writer.append(f\"Challenge/{fname}/{k}###{i}\", value.astype(target_dtype))\n",
    "        except KeyboardInterrupt:\n",
    "            raise\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    print(\"LongQT dataset\")\n",
    "    time.sleep(0.5)\n",
    "    import xml.etree.ElementTree as ET\n",
    "    ET.register_namespace(\"\",\"http://www3.medical.philips.com\")\n",
    "    all_files = (glob.glob(\"/home/guille/DADES/DADES/ECG/LONG_QT/LongQT_*/*.XML\") + \n",
    "                 glob.glob(\"/home/guille/DADES/DADES/ECG/LONG_QT/LongQT_*/*/*.XML\"))\n",
    "    head = \"{http://www3.medical.philips.com}\"\n",
    "    namespace = {\"xmlns:ns0\": \"http://www3.medical.philips.com\",\n",
    "                 \"xmlns:xsi\": \"http://www.w3.org/2001/XMLSchema-instance\",\n",
    "                 \"xsi:schemaLocation\": \"http://www3.medical.philips.com PhilipsECG.xsd\"}\n",
    "    for file in tqdm.tqdm(all_files):\n",
    "        try:\n",
    "            root,fname,ext = sak.splitrfe(file)\n",
    "            tree = ET.parse(file)\n",
    "            if len(tree.findall(\"FullDisclosure\")) != 0:\n",
    "                continue\n",
    "            fs = float(tree.findall(\"StripData/SampleRate\")[0].text)\n",
    "            ecg = {}\n",
    "            for lead in tree.findall(\"StripData/WaveformData\"):\n",
    "                ecg[lead.get(\"lead\").upper()] = np.array(lead.text.strip().split(\",\"),dtype=int)\n",
    "            ecg = np.array([ecg[k] for k in StandardHeader])\n",
    "            ecg = sak.signal.interpolate.interp1d(ecg,round(ecg.shape[1]*250/fs))\n",
    "            for k,lead in zip(StandardHeader,ecg):\n",
    "                if lead.size > max_size:\n",
    "                    data = skimage.util.view_as_windows(lead,(max_size,),step=window_step)\n",
    "                else:\n",
    "                    data = lead[None,]\n",
    "                for i,value in enumerate(data):\n",
    "                    if value.size < window: continue\n",
    "                    writer.append(f\"LongQT/{fname}/{k}###{i}\", (value/1000).astype(target_dtype))\n",
    "        except KeyboardInterrupt:\n",
    "            raise\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    print(\"THEW dataset\")\n",
    "    time.sleep(0.5)\n",
    "    all_files = glob.glob(\"/home/guille/DADES/DADES/ECG/THEWProject/*/*.ecg\")\n",
    "    for file in tqdm.tqdm(all_files):\n",
    "        try:\n",
    "            root,fname,ext = sak.splitrfe(file)\n",
    "            rt,stu_id = os.path.split(root)\n",
    "            ecg = ishneholterlib.Holter(file,check_valid=False)\n",
    "            ecg.load_data()\n",
    "            fs = ecg.sr\n",
    "            for lead in ecg.lead:\n",
    "                k = lead.spec_str().upper()\n",
    "                data = lead.data.copy()\n",
    "                data = sak.signal.interpolate.interp1d(data,target_fs*data.size//fs)\n",
    "                if data.size > max_size:\n",
    "                    data = skimage.util.view_as_windows(data,(max_size,),step=window_step)\n",
    "                else:\n",
    "                    data = data[None,]\n",
    "                for i,value in enumerate(data):\n",
    "                    if value.size < window: continue\n",
    "                    if np.all(np.abs(np.diff(value)) < 1e-6): continue\n",
    "                    writer.append(f\"THEW/{stu_id}_{fname}/{k}###{i}\", value.astype(target_dtype))\n",
    "        except KeyboardInterrupt:\n",
    "            raise\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    print(\"DeepFake dataset\")\n",
    "    time.sleep(0.5)\n",
    "    all_files = glob.glob(\"/home/guille/DADES/DADES/ECG/DeepFake/*.asc\")\n",
    "    for file in tqdm.tqdm(all_files):\n",
    "        try:\n",
    "            root,fname,ext = sak.splitrfe(file)\n",
    "            ecg = pd.read_csv(file,header=None,sep=\" \")\n",
    "            fs = 500\n",
    "            ecg = sak.signal.interpolate.interp1d(ecg.T,target_fs*ecg.shape[0]//fs)\n",
    "            for k,value in zip(StandardHeader,ecg):\n",
    "                k = k.upper()\n",
    "                if value.size < window: continue\n",
    "                writer.append(f\"DeepFake/{fname}/{k}###0\", (value/1000).astype(target_dtype))\n",
    "        except KeyboardInterrupt:\n",
    "            raise\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    print(\"SoO dataset\")\n",
    "    time.sleep(0.5)\n",
    "    all_files = glob.glob(\"/home/guille/DADES/DADES/ECG/Delineator/SoO/RETAG/*.txt\")\n",
    "    db = pd.read_csv('/home/guille/DADES/DADES/ECG/Delineator/SoO/DATABASE_MANUAL.csv')\n",
    "    for file in tqdm.tqdm(all_files):\n",
    "        try:\n",
    "            root,fname,ext = sak.splitrfe(file)\n",
    "            ecg = pd.read_csv(file,header=0,sep=\",\",index_col=0)\n",
    "            hea = list(map(lambda x: str(x).upper(), ecg.columns))\n",
    "            filt_id = (db[\"ID\"] == int(fname.split(\"-\")[0]))\n",
    "            fs = db[filt_id][\"Sampling_Freq\"].values[0]\n",
    "            ecg = np.round(sak.signal.interpolate.interp1d(ecg.T,target_fs*ecg.shape[0]//fs))/(2**15)\n",
    "            for k,lead in zip(hea,ecg):\n",
    "                k = k.upper()\n",
    "                if lead.size > max_size:\n",
    "                    lead = skimage.util.view_as_windows(lead,(max_size,),step=window_step)\n",
    "                else:\n",
    "                    lead = lead[None,]\n",
    "                for i,value in enumerate(lead):\n",
    "                    if value.size < window: continue\n",
    "                    writer.append(f\"SoO/{fname}/{k}###{i}\", value.astype(target_dtype))\n",
    "        except KeyboardInterrupt:\n",
    "            raise\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    print(\"EDB dataset\")\n",
    "    time.sleep(0.5)\n",
    "    all_files = glob.glob(\"/home/guille/DADES/DADES/ECG/PhysioNet/EDB/*.dat\")\n",
    "    for file in tqdm.tqdm(all_files):\n",
    "        try:\n",
    "            root,fname,ext = sak.splitrfe(file)\n",
    "            ecg,hea = wfdb.rdsamp(file[:-4])\n",
    "            fs = hea[\"fs\"]\n",
    "            ecg = sak.signal.interpolate.interp1d(ecg.T,target_fs*ecg.shape[0]//fs)\n",
    "            for k,lead in zip(hea[\"sig_name\"],ecg):\n",
    "                k = k.upper()\n",
    "                if lead.size > max_size:\n",
    "                    lead = skimage.util.view_as_windows(lead,(max_size,),step=window_step)\n",
    "                else:\n",
    "                    lead = lead[None,]\n",
    "                for i,value in enumerate(lead):\n",
    "                    if value.size < window: continue\n",
    "                    writer.append(f\"EDB/{fname}/{k}###{i}\", value.astype(target_dtype))\n",
    "        except KeyboardInterrupt:\n",
    "            raise\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    print(\"SVDB dataset\")\n",
    "    time.sleep(0.5)\n",
    "    all_files = glob.glob(\"/home/guille/DADES/DADES/ECG/PhysioNet/SVDB/*.dat\")\n",
    "    for file in tqdm.tqdm(all_files):\n",
    "        try:\n",
    "            root,fname,ext = sak.splitrfe(file)\n",
    "            ecg,hea = wfdb.rdsamp(file[:-4])\n",
    "            fs = hea[\"fs\"]\n",
    "            ecg = sak.signal.interpolate.interp1d(ecg.T,target_fs*ecg.shape[0]//fs)\n",
    "            for k,lead in zip(hea[\"sig_name\"],ecg):\n",
    "                k = k.upper()\n",
    "                if lead.size > max_size:\n",
    "                    lead = skimage.util.view_as_windows(lead,(max_size,),step=window_step)\n",
    "                else:\n",
    "                    lead = lead[None,]\n",
    "                for i,value in enumerate(lead):\n",
    "                    if value.size < window: continue\n",
    "                    writer.append(f\"SVDB/{fname}/{k}###{i}\", value.astype(target_dtype))\n",
    "        except KeyboardInterrupt:\n",
    "            raise\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    print(\"PredictAF dataset\")\n",
    "    time.sleep(0.5)\n",
    "    all_files = glob.glob(\"/home/guille/DADES/DADES/ECG/PredictAF/*/*/*.NHS\")\n",
    "    for file in tqdm.tqdm(all_files):\n",
    "        try:\n",
    "            root,fname,ext = sak.splitrfe(file)\n",
    "            rt,pat_id = os.path.split(root)\n",
    "            rt,stu_id = os.path.split(rt)\n",
    "            ecg,fs = src.reader.readNHS(file)\n",
    "            ecg = sak.signal.interpolate.interp1d(ecg.T,int(target_fs*ecg.shape[0]//fs)).T\n",
    "            for k,lead in zip(StandardHeader,ecg):\n",
    "                k = k.upper()\n",
    "                if lead.size > max_size:\n",
    "                    lead = skimage.util.view_as_windows(lead,(max_size,),step=window_step)\n",
    "                else:\n",
    "                    lead = lead[None,]\n",
    "                for i,value in enumerate(lead):\n",
    "                    if i < 5:\n",
    "                        continue\n",
    "                    if value.size < window: continue\n",
    "                    writer.append(f\"PredictAF/{stu_id}_{pat_id}/{k}###{i}\", value.astype(target_dtype))\n",
    "        except KeyboardInterrupt:\n",
    "            raise\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    print(\"Zhejiang dataset\")\n",
    "    time.sleep(0.5)\n",
    "    all_files = glob.glob(\"/home/guille/DADES/DADES/ECG/RubenDoste/ZhejiangDatabase/PVCVTRawECGData/*.csv\")\n",
    "    for file in tqdm.tqdm(all_files):\n",
    "        try:\n",
    "            root,fname,ext = sak.splitrfe(file)\n",
    "            if fname in [\"onsets\",\"offsets\"]: continue\n",
    "            ecg = pd.read_csv(file,header=0)\n",
    "            hea = list(ecg.columns)\n",
    "            fs = 2000\n",
    "            ecg = np.round(sak.signal.interpolate.interp1d(ecg.T,target_fs*ecg.shape[0]//fs))/(2**13)\n",
    "            for k,lead in zip(hea,ecg):\n",
    "                k = k.upper()\n",
    "                if lead.size > max_size:\n",
    "                    lead = skimage.util.view_as_windows(lead,(max_size,),step=window_step)\n",
    "                else:\n",
    "                    lead = lead[None,]\n",
    "                for i,value in enumerate(lead):\n",
    "                    if value.size < window: continue\n",
    "                    writer.append(f\"Zhejiang/{fname}/{k}###{i}\", value.astype(target_dtype))\n",
    "        except KeyboardInterrupt:\n",
    "            raise\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    print(\"HUVR_CARTO dataset\")\n",
    "    time.sleep(0.5)\n",
    "    all_files = glob.glob(\"/home/guille/DADES/DADES/EGMDelineator/Databases/CARTOEXPORT/*/*ECG_Export.txt\")\n",
    "    for file in tqdm.tqdm(all_files):\n",
    "        try:\n",
    "            root,fname,ext = sak.splitrfe(file)\n",
    "            rt,pat_id = os.path.split(root)\n",
    "            fs = 2000\n",
    "            signal,header = src.reader.Read_CARTO3_ECG(file)\n",
    "            channels = np.array(sak.map_upper([c.split(\"(\")[0].replace(\" \",\"\") for c in header[\"Channels\"]]))\n",
    "            idx_header = np.array([np.where(channels == c)[0][0] for c in StandardHeader])\n",
    "            signal = np.round(sak.signal.interpolate.interp1d(signal[idx_header],target_fs*signal.shape[1]//fs))/(2**10)\n",
    "            for k,lead in zip(StandardHeader,signal):\n",
    "                k = k.upper()\n",
    "                if lead.size > max_size:\n",
    "                    lead = skimage.util.view_as_windows(lead,(max_size,),step=window_step)\n",
    "                else:\n",
    "                    lead = lead[None,]\n",
    "                for i,value in enumerate(lead):\n",
    "                    if value.size < window: continue\n",
    "                    writer.append(f\"HUVR_CARTO/{pat_id}_{fname}/{k}###{i}\", value.astype(target_dtype))\n",
    "        except KeyboardInterrupt:\n",
    "            raise\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "time.sleep(0.5)\n",
    "print(\"Done.\")\n",
    "time.sleep(0.5)\n",
    "!du -sh /media/guille/DADES/DADES/ECG/unsupervised.fleet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422 ns ± 0.346 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n",
      "1.64 ms ± 32 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "with pathlib.Path(\"/media/guille/DADES/DADES/ECG/unsupervised_16.fleet\").open('rb') as fhandle, fleetfmt.FileReader(fhandle) as reader:\n",
    "    # get keys\n",
    "    dkeys = list(reader.keys())\n",
    "\n",
    "    # get random value\n",
    "    %timeit key = random.choice(dkeys)\n",
    "    %timeit key = random.choice(dkeys); reader.read(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MUSE': 127752,\n",
       " 'Brugada': 92364,\n",
       " 'Fallot': 23292,\n",
       " 'HCM': 1836,\n",
       " 'Challenge': 519984,\n",
       " 'LongQT': 9624,\n",
       " 'THEW': 2194152,\n",
       " 'DeepFake': 1200000,\n",
       " 'SoO': 6492,\n",
       " 'EDB': 16560,\n",
       " 'SVDB': 3588,\n",
       " 'PredictAF': 210738,\n",
       " 'Zhejiang': 4008,\n",
       " 'HUVR_CARTO': 247416}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_keys = {}\n",
    "for key in dkeys:\n",
    "    DB = key.split(\"/\")[0]\n",
    "    \n",
    "    if DB not in all_keys:\n",
    "        all_keys[DB] = 0\n",
    "        \n",
    "    all_keys[DB] += 1\n",
    "all_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
